{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "來源 https://github.com/IS2AI/thermal-facial-landmarks-detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img src=\"resources/images/ROI.jpg\" width=\"200\"/></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading dlib thermal face detector...\n",
      "[INFO] loading facial landmark predictor...\n"
     ]
    }
   ],
   "source": [
    "from imutils import face_utils\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import os \n",
    "\n",
    "image_path = './test_images/'\n",
    "model_path = './models/'\n",
    "upsampling_times = 1\n",
    "\n",
    "\n",
    "# load the face detector (HOG-SVM)\n",
    "print(\"[INFO] loading dlib thermal face detector...\")\n",
    "detector = dlib.simple_object_detector(os.path.join(model_path, \"dlib_face_detector.svm\"))\n",
    "\n",
    "# load the facial landmarks predictor\n",
    "print(\"[INFO] loading facial landmark predictor...\")\n",
    "predictor = dlib.shape_predictor(os.path.join(model_path, \"dlib_landmark_predictor.dat\"))\n",
    "\n",
    "# grab paths to the images\n",
    "imagePaths = list(paths.list_files(image_path))\n",
    "\n",
    "gray_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing image: 1/2\n",
      "[INFO] Processing image: 2/2\n"
     ]
    }
   ],
   "source": [
    "# loop over the images\n",
    "for ind, imagePath in enumerate(imagePaths, 1):\n",
    "\n",
    "\t#ind=1\n",
    "\tprint(\"[INFO] Processing image: {}/{}\".format(ind, len(imagePaths)))\n",
    "\t# load the \n",
    "\timage = cv2.imread(imagePath)\n",
    "\n",
    "\t# resize the image\n",
    "\timage = imutils.resize(image, height=600)\n",
    "\n",
    "\t# copy the image\n",
    "\timage_copy = image.copy()\n",
    "\n",
    "\t# convert the image to grayscale\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGRA2GRAY)\n",
    "\t\n",
    "\t# detect faces in the image \n",
    "\n",
    "\trects = detector(image, upsample_num_times=upsampling_times)\t\n",
    "\n",
    "\tfor rect in rects:\n",
    "\t\t# convert the dlib rectangle into an OpenCV bounding box and\n",
    "\t\t# draw a bounding box surrounding the face\n",
    "\t\t(x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "\t\tcv2.rectangle(image_copy, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "\t\t# predict the location of facial landmark coordinates, \n",
    "\t\t# then convert the prediction to an easily parsable NumPy array\n",
    "\t\tshape = predictor(image, rect)\n",
    "\t\tshape = face_utils.shape_to_np(shape)\n",
    "\n",
    "\t\tnext_to_nose_tip = 29\n",
    "\t\t#取得特定點的顏色\n",
    "\t\tselected_point_y =  shape[next_to_nose_tip][1]\n",
    "\t\tselected_point_x =  shape[next_to_nose_tip][0]\n",
    "\t\t#selected_point = image_copy[selected_point_y, selected_point_x]\n",
    "\t\t#color = (selected_point[0],selected_point[1],selected_point[2])\n",
    "\t\t#color = tuple([int(x) for x in color]) \n",
    "\t\tgray_color = image[selected_point_y, selected_point_x]\n",
    "\t\tgray_list.append(gray_color)\n",
    "\t\tcolor = (gray_color,gray_color,gray_color)\n",
    "\t\tcolor = tuple([int(x) for x in color]) \n",
    "\n",
    "\t\t#左側臉頰加點\n",
    "\t\tpoint_3_x =  shape[2][0]\n",
    "\t\tpoint_3_y =  shape[2][1]\n",
    "\t\tpoint_32_x =  shape[31][0]\n",
    "\t\tpoint_32_y =  shape[31][1]\n",
    "\t\tpoint_left_cheek_x = np.int16(0.7*point_3_x+0.3*point_32_x)\n",
    "\t\tpoint_left_cheek_y = np.int16(0.7*point_3_y+0.3*point_32_y)\n",
    "\t\tshape = np.vstack([shape, [point_left_cheek_x,point_left_cheek_y]])\n",
    "\t\tpoint_left_nose_x = np.int16(0.3*point_3_x+0.7*point_32_x)\n",
    "\t\tpoint_left_nose_y = np.int16(0.3*point_3_y+0.7*point_32_y)\n",
    "\t\tshape = np.vstack([shape, [point_left_nose_x,point_left_nose_y]])\n",
    "\t\t#右側臉頰加點\n",
    "\t\tpoint_15_x =  shape[14][0]\n",
    "\t\tpoint_15_y =  shape[14][1]\n",
    "\t\tpoint_36_x =  shape[35][0]\n",
    "\t\tpoint_36_y =  shape[35][1]\n",
    "\t\tpoint_right_cheek_x = np.int16(0.7*point_15_x+0.3*point_36_x)\n",
    "\t\tpoint_right_cheek_y = np.int16(0.7*point_15_y+0.3*point_36_y)\n",
    "\t\tshape = np.vstack ([shape, [point_right_cheek_x,point_right_cheek_y]])\n",
    "\t\tpoint_right_nose_x = np.int16(0.3*point_15_x+0.7*point_36_x)\n",
    "\t\tpoint_right_nose_y = np.int16(0.3*point_15_y+0.7*point_36_y)\n",
    "\t\tshape = np.vstack ([shape, [point_right_nose_x,point_right_nose_y]])\n",
    "\n",
    "\t\t#forehead\n",
    "\t\tpoint_22_x =  shape[21][0]\n",
    "\t\tpoint_22_y =  shape[21][1]\n",
    "\t\tpoint_23_x =  shape[22][0]\n",
    "\t\tpoint_23_y =  shape[22][1]\n",
    "\t\tpoint_28_x =  shape[27][0]\n",
    "\t\tpoint_28_y =  shape[27][1]\n",
    "\t\tpoint_fore_head_x = np.int16(point_22_x+ point_23_x- point_28_x)\n",
    "\t\tpoint_fore_head_y = np.int16(0.75*point_22_y+ 0.75*point_23_y- 0.5*point_28_y)\t\n",
    "\t\tshape = np.vstack([shape, [point_fore_head_x,point_fore_head_y]])\t\n",
    "\t\t\n",
    "\t\t#throat\n",
    "\t\tpoint_9_x =  shape[8][0]\n",
    "\t\tpoint_9_y =  shape[8][1]\n",
    "\t\tpoint_52_x =  shape[51][0]\n",
    "\t\tpoint_52_y =  shape[51][1]\n",
    "\t\tpoint_chin_x = np.int16(0.5*point_9_x+0.5*point_52_x)\n",
    "\t\tpoint_chin_y = np.int16(0.5*point_9_y+0.5*point_52_y)\n",
    "\t\tshape = np.vstack ([shape, [point_chin_x,point_chin_y]])\t\n",
    "\n",
    "\t\tif shape[30][0]-shape[27][0]>0:\n",
    "\t\t\tpoint_8_x =  shape[7][0]\n",
    "\t\t\tpoint_8_y =  shape[7][1]\n",
    "\t\t\tpoint_throat_x = np.int16(1.4*point_8_x-0.4*point_52_x)\n",
    "\t\t\tpoint_throat_y = np.int16(1.4*point_8_y-0.4*point_52_y)\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tpoint_10_x =  shape[9][0]\n",
    "\t\t\tpoint_10_y =  shape[9][1]\n",
    "\t\t\tpoint_throat_x = np.int16(1.4*point_10_x-0.4*point_52_x)\n",
    "\t\t\tpoint_throat_y = np.int16(1.4*point_10_y-0.4*point_52_y)\t\n",
    "\t\tshape = np.vstack ([shape, [point_throat_x,point_throat_y]])\n",
    "\t\t# loop over the (x, y)-coordinates from our dlib shape\n",
    "\t\t# predictor model draw them on the image\n",
    "\t\tpoint_color = (255, 0, 0)\n",
    "\t\tpoint_size = 2\n",
    "\t\t# for i in range(len(shape)):\n",
    "\t\t# \t(sx, sy) = shape[i]\n",
    "\t\t# \tcv2.circle(image_copy, (sx, sy), point_size, point_color, -1)\n",
    "\t\tindex_of_left_eyebrow_outer = 18\n",
    "\t\tindex_of_right_eyebrow_outer = 25\n",
    "\t\tindex_of_left_eyebrow_inner = 21\n",
    "\t\tindex_of_right_eyebrow_inner = 22\n",
    "\t\tindex_of_fore_head = 58\n",
    "\t\tindex_of_upper_nose = 28\n",
    "\t\tindex_of_middle_nose = 29\n",
    "\t\tindex_of_nose_tip = 30\n",
    "\t\tindex_of_left_nostril = 32\n",
    "\t\tindex_of_right_nostril = 34\n",
    "\t\tindex_of_left_nose = 55\n",
    "\t\tindex_of_right_nose = 57\n",
    "\t\tindex_of_left_cheek = 54\n",
    "\t\tindex_of_right_cheek = 56\n",
    "\t\tindex_of_chin = 59\n",
    "\t\tindex_of_throat = 60\n",
    "\t\tindex_of_left_lip = 48\n",
    "\t\tindex_of_upper_lip_outer = 49\n",
    "\t\tindex_of_upper_lip = 52\n",
    "\t\tindex_of_right_lip = 50\n",
    "\t\tindex_of_lower_iip_outer = 51\n",
    "\t\tindex_of_lower_iip = 53\n",
    "\t\tpoint_list =[index_of_left_eyebrow_outer,index_of_right_eyebrow_outer,index_of_left_eyebrow_inner,index_of_right_eyebrow_inner,index_of_fore_head,index_of_upper_nose,index_of_middle_nose,index_of_nose_tip,index_of_left_nostril,index_of_right_nostril,index_of_left_nose,index_of_right_nose,index_of_left_cheek,index_of_right_cheek,index_of_chin,index_of_throat,index_of_left_lip,index_of_upper_lip_outer,index_of_upper_lip,index_of_right_lip,index_of_lower_iip_outer,index_of_lower_iip]\n",
    "\t\tfor index in range(len(point_list)):\n",
    "\t\t\tcv2.circle(image_copy, shape[point_list[index]], point_size, point_color, -1)\t\t\t\n",
    "\t\n",
    "\n",
    "\t# show the image\n",
    "\n",
    "\t#image_copy_resize = cv2.resize(image_copy,(300*5,168*5))\n",
    "\tcv2.imshow(\"Image\", image_copy)\n",
    "\tkey = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "\t# if the `q` key was pressed, break from the loop\n",
    "\tif key == ord(\"q\"): \n",
    "\t\tbreak\n",
    "\n",
    "# do a bit cleanup \n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyVHR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
